{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d6b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_landmarks(landmarks, handedness):\n",
    "    landmarks = np.array(landmarks)\n",
    "\n",
    "    # Translate so that wrist is at origin\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "\n",
    "    # Scale so that distance between wrist and middle finger MCP is 1\n",
    "    mcp_index = 9  # Middle finger MCP landmark index\n",
    "    scale = np.linalg.norm(landmarks[mcp_index]) # euclidean distance from the origin (wrist)\n",
    "    if scale > 0:\n",
    "        landmarks = landmarks / scale\n",
    "    \n",
    "    # Mirror left hands\n",
    "    if handedness == \"Left\":\n",
    "        landmarks[:, 0]  =  -landmarks[:, 0]\n",
    "\n",
    "    # rotate all landmarks to point up\n",
    "    rotated_landmarks = normalize_rotation(landmarks)\n",
    "\n",
    "    return rotated_landmarks.tolist()\n",
    "\n",
    "def normalize_rotation(landmarks):\n",
    "    # Reference vector: from wrist (now at origin) to middle finger MCP\n",
    "    reference_vector = landmarks[9]  # Middle finger MCP (wrist is at origin)\n",
    "    \n",
    "    # Current angle of reference vector\n",
    "    current_angle = np.arctan2(reference_vector[1], reference_vector[0])\n",
    "    \n",
    "    # Target angle (pointing up in image coordinates = -90 degrees = -pi/2)\n",
    "    # Note: In image coordinates, Y increases downward, so \"up\" is negative Y\n",
    "    target_angle = -np.pi / 2\n",
    "    \n",
    "    # Calculate rotation needed\n",
    "    rotation_angle = target_angle - current_angle\n",
    "    \n",
    "    # Apply rotation\n",
    "    cos_a = np.cos(rotation_angle)\n",
    "    sin_a = np.sin(rotation_angle)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_a, -sin_a],\n",
    "        [sin_a, cos_a]\n",
    "    ])\n",
    "    \n",
    "    rotated_landmarks = (rotation_matrix @ landmarks.T).T\n",
    "    \n",
    "    return rotated_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6e3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_direction(landmark_list):\n",
    "    wrist = np.array(landmark_list[0])\n",
    "    index_mcp = np.array(landmark_list[5])\n",
    "    middle_mcp = np.array(landmark_list[9])\n",
    "    index_tip = np.array(landmark_list[8])\n",
    "    middle_tip = np.array(landmark_list[12])\n",
    "\n",
    "    palm_center = (wrist + index_mcp + middle_mcp) / 3\n",
    "    finger_tip_avg = (index_tip + middle_tip) / 2\n",
    "    finger_dir = finger_tip_avg - palm_center\n",
    "\n",
    "    angle = np.arctan2(finger_dir[1], finger_dir[0])  # radians, range [-pi, pi]\n",
    "    return angle\n",
    "\n",
    "def retrieve_direction(angle):\n",
    "    # Normalize angle to [-pi, pi]\n",
    "    angle = (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "    \n",
    "    # Define thresholds in radians\n",
    "    right_thresh = np.pi / 4          # 45 degrees\n",
    "    left_thresh = 3 * np.pi / 4       # 135 degrees\n",
    "    \n",
    "    if -right_thresh <= angle <= right_thresh:\n",
    "        return \"Right\"\n",
    "    elif angle >= left_thresh or angle <= -left_thresh:\n",
    "        return \"Left\"\n",
    "    elif right_thresh < angle < left_thresh:\n",
    "        return \"Down\"\n",
    "    else:\n",
    "        return \"Up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d681ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_normalized_landmarks(norm_landmarks, size=300):\n",
    "    canvas = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "\n",
    "    # draw axes\n",
    "    center = size // 2\n",
    "    cv2.line(canvas, (center, 0), (center, size), (50, 50, 50), 1)\n",
    "    cv2.line(canvas, (0, center), (size, center), (50, 50, 50), 1)\n",
    "\n",
    "    for x, y in norm_landmarks:\n",
    "        px = int((x + 2) / 4 * size)\n",
    "        py = int((y + 2) / 4 * size)\n",
    "\n",
    "        # invert Y for display\n",
    "        # py = size - py\n",
    "\n",
    "        # clamp just in case\n",
    "        if 0 <= px < size and 0 <= py < size:\n",
    "            cv2.circle(canvas, (px, py), 4, (0, 255, 0), -1)\n",
    "\n",
    "    return canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effef649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import json\n",
    "\n",
    "# given that this file is at project-root/notebooks\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "MODELS_DIR = PROJECT_ROOT / 'shared_artifacts/models'\n",
    "\n",
    "DETECTOR_PATH = MODELS_DIR / 'hand_landmarker.task'\n",
    "ACTIVE_MODEL_PATH = MODELS_DIR / 'active_model.json'\n",
    "\n",
    "with open(str(ACTIVE_MODEL_PATH)) as f:\n",
    "    data = json.load(f)\n",
    "    MODEL_FILE = data[\"model_file\"]\n",
    "    CLASS_NAMES = data[\"class_names\"]\n",
    "\n",
    "MODEL_PATH = MODELS_DIR / MODEL_FILE\n",
    "\n",
    "model = keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "\n",
    "options = HandLandmarkerOptions(base_options=BaseOptions(model_asset_path=str(DETECTOR_PATH)),\n",
    "                                num_hands=1,\n",
    "                                running_mode=VisionRunningMode.VIDEO)\n",
    "\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "    # Open default camera (0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)\n",
    "\n",
    "        timestamp_ms = int(time.time() * 1000)\n",
    "\n",
    "        results = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "\n",
    "        if results.hand_landmarks:\n",
    "            landmarks = results.hand_landmarks[0]\n",
    "            handedness_category = results.handedness[0][0]\n",
    "            handedness = handedness_category.category_name\n",
    "            confidence = handedness_category.score\n",
    "\n",
    "\n",
    "            landmark_list = []\n",
    "            for lm in landmarks:\n",
    "                landmark_list.append([lm.x, lm.y])\n",
    "\n",
    "            angle = compute_direction(landmark_list)\n",
    "            direction = retrieve_direction(angle)\n",
    "\n",
    "            # Debugging purposes\n",
    "            h, w, _ = frame.shape\n",
    "            for lm in landmark_list:\n",
    "                lx = int(lm[0] * w)\n",
    "                ly = int(lm[1] * h)\n",
    "                cv2.circle(frame, (lx, ly), 5, (0, 255, 0), -1)\n",
    "\n",
    "            normalized_landmarks = normalize_landmarks(landmark_list, handedness)\n",
    "\n",
    "            # Debugging purposes\n",
    "            norm_canvas = draw_normalized_landmarks(normalized_landmarks)\n",
    "            cv2.imshow(\"Normalized landmarks\", norm_canvas)\n",
    "\n",
    "            input_vector = np.array(normalized_landmarks, dtype=np.float32).flatten() # (42,)\n",
    "\n",
    "            input_vector = np.expand_dims(input_vector, axis=0) # (1, 42)\n",
    "\n",
    "            predictions = model.predict(input_vector, verbose=0)\n",
    "\n",
    "            predicted_idx = np.argmax(predictions[0])\n",
    "            confidence = predictions[0][predicted_idx]\n",
    "\n",
    "            predicted_gesture = CLASS_NAMES[predicted_idx]\n",
    "\n",
    "            print(\"Handedness: \", handedness)\n",
    "            print(f\"Predicted: {predicted_gesture}; Confidence: {confidence}; Direction: {direction}\")\n",
    "\n",
    "        cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
