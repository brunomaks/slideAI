{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b166cac",
   "metadata": {},
   "source": [
    "# Data Ingestion with Landmark Extraction\n",
    "\n",
    "This notebook performs end-to-end data ingestion starting from raw gesture images.\n",
    "It extracts hand landmarks using MediaPipe, validates and normalizes them, and\n",
    "stores the processed representation in a SQLite database.\n",
    "\n",
    "The resulting database is consumed by downstream model training pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b44117c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "DB_PATH = Path.cwd() / \"shared_artifacts\" / \"data\" / \"landmarks.sqlite\"\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_IMAGES_PATH = Path(\"shared_artifacts/images/hagrid_30k\")\n",
    "\n",
    "LANDMARK_DETECTOR_PATH = Path('shared_artifacts/models/hand_landmarker.task')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gestures_raw (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        gesture TEXT NOT NULL,\n",
    "        image_path TEXT NOT NULL,\n",
    "        handedness TEXT NOT NULL,\n",
    "        landmarks TEXT NOT NULL CHECK(json_valid(landmarks))\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gestures_processed (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        gesture TEXT NOT NULL,\n",
    "        image_path TEXT NOT NULL,\n",
    "        handedness TEXT NOT NULL,\n",
    "        landmarks TEXT NOT NULL CHECK(json_valid(landmarks))\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "create_database(DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "631f4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_tasks = mp.tasks\n",
    "BaseOptions = mp_tasks.BaseOptions\n",
    "VisionRunningMode = mp_tasks.vision.RunningMode\n",
    "HandLandmarkerOptions = mp_tasks.vision.HandLandmarkerOptions\n",
    "HandLandmarker = mp_tasks.vision.HandLandmarker\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=str(LANDMARK_DETECTOR_PATH)),\n",
    "    num_hands=1,\n",
    "    running_mode=VisionRunningMode.IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3ae1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks(image_path, landmarker):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)\n",
    "    results = landmarker.detect(mp_image)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56a11a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_raw_landmarks():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    skipped = 0\n",
    "    inserted = 0\n",
    "\n",
    "    with HandLandmarker.create_from_options(options) as landmarker:\n",
    "        for gesture_folder in os.listdir(RAW_IMAGES_PATH):\n",
    "            gesture_path = RAW_IMAGES_PATH / gesture_folder\n",
    "\n",
    "            if not gesture_path.is_dir():\n",
    "                continue\n",
    "\n",
    "            for file in tqdm.tqdm(os.listdir(gesture_path), desc=f\"Extracting {gesture_folder}\"):\n",
    "                image_path = gesture_path / file\n",
    "                results = extract_landmarks(image_path, landmarker)\n",
    "\n",
    "                if not results.hand_landmarks:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                record = {\n",
    "                    \"gesture\": gesture_folder,\n",
    "                    \"image_path\": str(image_path.relative_to(RAW_IMAGES_PATH)),\n",
    "                    \"handedness\": results.handedness[0][0].category_name,\n",
    "                    \"landmarks\": [[lm.x, lm.y, lm.z] for lm in results.hand_landmarks[0]]\n",
    "                }\n",
    "\n",
    "                cur.execute(\"\"\"\n",
    "                INSERT INTO gestures_raw\n",
    "                (gesture, image_path, handedness, landmarks)\n",
    "                VALUES (?, ?, ?, ?)\n",
    "                \"\"\", (\n",
    "                    record[\"gesture\"],\n",
    "                    record[\"image_path\"],\n",
    "                    record[\"handedness\"],\n",
    "                    json.dumps(record[\"landmarks\"])\n",
    "                ))\n",
    "\n",
    "                inserted += 1\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Inserted {inserted} raw samples\")\n",
    "    print(f\"Skipped {skipped} images with no detected landmarks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2af518ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1766774680.410229   16151 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766774680.425323   16151 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Extracting stop:   0%|          | 0/1748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting stop: 100%|██████████| 1748/1748 [00:57<00:00, 30.46it/s]\n",
      "Extracting like: 100%|██████████| 1732/1732 [00:56<00:00, 30.49it/s]\n",
      "Extracting two_up_inverted: 100%|██████████| 1765/1765 [00:59<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 4652 raw samples\n",
      "Skipped 593 images with no detected landmarks\n"
     ]
    }
   ],
   "source": [
    "ingest_raw_landmarks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cfa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make wrist to be at the origin (0,0), scale all the landmarks to similar scale, \n",
    "# flip gestures performed with left hand to only consider right hand gestures\n",
    "def normalize_landmarks(landmarks, handedness):\n",
    "    landmarks = np.array(landmarks)[:, :2]\n",
    "\n",
    "    wrist = landmarks[0]\n",
    "    landmarks = landmarks - wrist\n",
    "\n",
    "    scale = np.linalg.norm(landmarks[9])\n",
    "    if scale > 0:\n",
    "        landmarks = landmarks / scale\n",
    "\n",
    "    if handedness == \"Left\":\n",
    "        landmarks[:, 0] = -landmarks[:, 0]\n",
    "\n",
    "    return normalize_rotation(landmarks)\n",
    "\n",
    "# rotate all the landmarks to point in the same direction (down)\n",
    "def normalize_rotation(landmarks):\n",
    "    reference_vector = landmarks[9]  # Middle finger MCP\n",
    "    current_angle = np.arctan2(reference_vector[1], reference_vector[0])\n",
    "    target_angle = -np.pi / 2\n",
    "    rotation_angle = target_angle - current_angle\n",
    "    return rotate_landmarks(landmarks, rotation_angle)\n",
    "\n",
    "# rotates around the origin (0,0) - wrist!\n",
    "def rotate_landmarks(landmarks, angle):\n",
    "    R = np.array([\n",
    "        [np.cos(angle), -np.sin(angle)],\n",
    "        [np.sin(angle),  np.cos(angle)]\n",
    "    ])\n",
    "    return landmarks @ R.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaadbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_landmark_normalization(normalized_landmarks):\n",
    "    hand_sizes = []\n",
    "\n",
    "    for i, entry in enumerate(normalized_landmarks):\n",
    "        tag = f\"Sample {i}\"\n",
    "        landmarks = np.array(entry)\n",
    "        x = landmarks[:, 0]\n",
    "        y = landmarks[:, 1]\n",
    "\n",
    "        # 1. Wrist near origin\n",
    "        assert abs(x[0]) < 1e-4, f\"{tag} wrist x not zero: {x[0]}\"\n",
    "        assert abs(y[0]) < 1e-4, f\"{tag} wrist y not zero: {y[0]}\"\n",
    "\n",
    "        # 2. Range check\n",
    "        assert x.min() > -3 and x.max() < 3, f\"{tag} x out of range: min={x.min()}; max={x.max()}\"\n",
    "        assert y.min() > -3 and y.max() <= 0, f\"{tag} y out of range: min={y.min()}; max={y.max()}\"\n",
    "\n",
    "        # 3. Fingers mostly above wrist (Y negative)\n",
    "        tip_ids = [4, 8, 12, 16, 20]\n",
    "        num_down = sum(y[i] > 0 for i in tip_ids)\n",
    "        assert num_down <= 1, f\"{tag} too many fingertips below wrist\"\n",
    "\n",
    "        # 4. Collect scale (index fingertip distance)\n",
    "        hand_size = np.linalg.norm([x[9], y[9]])\n",
    "        hand_sizes.append(hand_size)\n",
    "\n",
    "    # 5. Global scale consistency check\n",
    "    hand_sizes = np.array(hand_sizes)\n",
    "    assert hand_sizes.std() < 0.5, f\"Global scale inconsistency (std={hand_sizes.std():.2f})\"\n",
    "\n",
    "    print(f\"Landmarks passed validation ({len(normalized_landmarks)} samples)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d748393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_normalized_landmarks():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    rows = cur.execute(\"\"\"\n",
    "        SELECT * FROM gestures_raw\n",
    "    \"\"\").fetchall()\n",
    "\n",
    "    inserted = 0\n",
    "    discarded = 0\n",
    "\n",
    "    hand_sizes = []\n",
    "\n",
    "    for _, gesture, image_path, handedness, landmarks_json in rows:\n",
    "        landmarks = json.loads(landmarks_json)\n",
    "        normalized = normalize_landmarks(landmarks, handedness)\n",
    "\n",
    "        # 1. Check that wrists live at the origin\n",
    "        wrist = normalized[0]\n",
    "        if not np.allclose(wrist, [0, 0], atol=1e-3):\n",
    "            discarded += 1\n",
    "            continue\n",
    "\n",
    "        # 2. Make sure all the landmarks are contained within specific intervals\n",
    "        # x-interval: (-3, 3), y-interval: (-3, 0)\n",
    "        xs, ys = normalized[:, 0], normalized[:, 1]\n",
    "        if min(xs) < -3 or max(xs) > 3 or min(ys) < -3 or max(ys) > 0:\n",
    "            discarded += 1\n",
    "            continue\n",
    "\n",
    "        # 3. Fingers mostly above wrist (y negative)\n",
    "        tip_ids = [4, 8, 12, 16, 20]  # thumb and fingertips indices (from mediapipe handlandmarker)\n",
    "        num_down = sum(ys[i] > 0 for i in tip_ids)\n",
    "        if num_down > 1:\n",
    "            discarded += 1\n",
    "            continue\n",
    "\n",
    "        # 4.1 Collect scale (distance from wrist to middle finger MCP)\n",
    "        hand_size = np.linalg.norm(normalized[9])\n",
    "        hand_sizes.append(hand_size)\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "        INSERT INTO gestures_processed\n",
    "        (gesture, image_path, handedness, landmarks)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            gesture,\n",
    "            image_path,\n",
    "            handedness,\n",
    "            json.dumps(normalized.tolist())\n",
    "        ))\n",
    "\n",
    "        inserted += 1\n",
    "\n",
    "    # 4.2 Global scale consistency check\n",
    "    if hand_sizes:\n",
    "        hand_sizes = np.array(hand_sizes)\n",
    "        std_scale = hand_sizes.std()\n",
    "        assert std_scale < 0.5, f\"Global scale inconsistency (std={std_scale:.2f})\"\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Inserted {inserted} processed samples\")\n",
    "    print(f\"Discarded {discarded} invalid samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c561c879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 4588 processed samples\n",
      "Discarded 64 invalid samples\n"
     ]
    }
   ],
   "source": [
    "ingest_normalized_landmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e919e4",
   "metadata": {},
   "source": [
    "Finally, lets see what we have inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "cur = conn.cursor()\n",
    "\n",
    "rows = cur.execute(\"\"\"\n",
    "    SELECT * FROM gestures_processed\n",
    "\"\"\").fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b59481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
