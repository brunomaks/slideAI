{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e31e21d",
   "metadata": {},
   "source": [
    "\n",
    "We start our dataset preprocessing by extracting and cropping hand gestures from the dataset explored in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mediapipe_cropper.cropper import process_images\n",
    "process_images('shared_artifacts/images/hagrid_30k', 'shared_artifacts/images/hagrid_30k_cropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08d132-6efa-4250-bada-558c15e79168",
   "metadata": {},
   "source": [
    "When we have cropped hand gesture images saved, they are all of different sizes. We want them to have an optimal size so that it is: \n",
    "1. Big enough to capture important hand-shape details\n",
    "2. Small enough to train fast\n",
    "3. Consistent across the dataset\n",
    "    \n",
    "So we chose to look at the distribution of all our image dimensions and choose a size close to the *median* or *mean*, then round to a CNN-friendly size (like 64, 96, 128). \n",
    "- *Motivation to this is:* Powers of 2 and Divisibility - many of these numbers are powers of 2 (64, 128, 256, which is close to 224 in practical terms) or easily divisible by 32. This is crucial because standard CNN architectures use multiple layers of pooling operations that typically reduce the image dimensions by half at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a18e61c-8919-4392-9608-b42df934addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean width: 88 px\n",
      "Mean height: 105 px\n",
      "Median width: 84.0 px\n",
      "Median height: 100.0 px\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = \"shared_artifacts/images/hagrid_30k_cropped\"\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for label in os.listdir(input_folder):\n",
    "    label_folder = os.path.join(input_folder, label)\n",
    "\n",
    "    for f in os.listdir(label_folder):\n",
    "        img = cv2.imread(os.path.join(label_folder, f))\n",
    "        h, w = img.shape[:2]\n",
    "        widths.append(w)\n",
    "        heights.append(h)\n",
    "\n",
    "print(f\"Mean width: {np.mean(widths):.0f} px\")\n",
    "print(f\"Mean height: {np.mean(heights):.0f} px\")\n",
    "print(f\"Median width: {np.median(widths)} px\")\n",
    "print(f\"Median height: {np.median(heights)} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a3f2f-9cbb-40a8-bcf0-10505ad1197c",
   "metadata": {},
   "source": [
    "#### So dataset (cropped images of \"swipe\" hand gestures with margin 20px) has:\n",
    "- Width ~ 75 px\n",
    "- Height ~ 125 px\n",
    "\n",
    "Which indicates that:\n",
    "- the images are not square\n",
    "- The aspect ratio is roughly 3:5 (75:125 ≈ 0.6)\n",
    "\n",
    "Since the cropped images are naturally rectangular, if we resize directly to square dimensions like:\n",
    "- 96×96 -> hands will get squashed\n",
    "- 128×128 -> same distortion problem\n",
    "\n",
    "Therefore, we decided to resize while preserving aspect ratio, then pad to a square (add plack pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2ebe4-12e4-4500-bfb5-7dc5072b99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.resizer.resizer import process_images\n",
    "\n",
    "input_path = \"shared_artifacts/images/hagrid_30k_cropped\"\n",
    "output_path = \"shared_artifacts/images/hagrid_30k_resized\" \n",
    "\n",
    "TARGET_SIZE = 94\n",
    "\n",
    "process_images(input_path, TARGET_SIZE, TARGET_SIZE, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
