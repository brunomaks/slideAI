{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e08d132-6efa-4250-bada-558c15e79168",
   "metadata": {},
   "source": [
    "When we have cropped hand gesture images saved, they are all of different sizes. We want them to have an optimal size so that it is: \n",
    "1. Big enough to capture important hand-shape details\n",
    "2. Small enough to train fast\n",
    "3. Consistent across the dataset\n",
    "    \n",
    "So we chose to look at the distribution of all our image dimensions and choose a size close to the *median* or *mean*, then round to a CNN-friendly size (like 64, 96, 128). \n",
    "- *Motivation to this is:* Powers of 2 and Divisibility - many of these numbers are powers of 2 (64, 128, 256, which is close to 224 in practical terms) or easily divisible by 32. This is crucial because standard CNN architectures use multiple layers of pooling operations that typically reduce the image dimensions by half at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18e61c-8919-4392-9608-b42df934addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = \"./mediapipe_cropper/output\"\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "count = 0\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    img = cv2.imread(os.path.join(input_folder, filename))\n",
    "    h, w = img.shape[:2]\n",
    "    widths.append(w)\n",
    "    heights.append(h)\n",
    "\n",
    "print(\"Mean width: \", np.mean(widths), \"px\")\n",
    "print(\"Mean height: \", np.mean(heights), \"px\")\n",
    "print(\"Median width: \", np.median(widths), \"px\")\n",
    "print(\"Median height: \", np.median(heights), \"px\")\n",
    "\n",
    "print(\"Min size:\", min(widths), \"X\", min(heights), \"px\")\n",
    "print(\"Max size:\", max(widths), \"X\", max(heights), \"px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a3f2f-9cbb-40a8-bcf0-10505ad1197c",
   "metadata": {},
   "source": [
    "#### So dataset (cropped images of \"swipe\" hand gestures with margin 20px) has:\n",
    "- Width ~ 75 px\n",
    "- Height ~ 125 px\n",
    "\n",
    "Which indicates that:\n",
    "- the images are not square\n",
    "- The aspect ratio is roughly 3:5 (75:125 ≈ 0.6)\n",
    "\n",
    "Since the cropped images are naturally rectangular, if we resize directly to square dimensions like:\n",
    "- 96×96 -> hands will get squashed\n",
    "- 128×128 -> same distortion problem\n",
    "\n",
    "Therefore, we decided to resize while preserving aspect ratio, then pad to a square (add plack pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2ebe4-12e4-4500-bfb5-7dc5072b99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse \n",
    "import sys\n",
    "\n",
    "# Simulate command line arguments\n",
    "sys.argv = ['script.py', '-input', './mediapipe_cropper/output/', '-output', './resizer/output/']\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "#-i INPUT -o OUTPUT \n",
    "parser.add_argument(\"-input\", \"--input\", dest = \"input\", default = \"./input/\", help=\"Path to input folder\")\n",
    "parser.add_argument(\"-output\", \"--output\", dest = \"output\", default = \"./output/\", help=\"Path to output folder\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "input_path = args.input\n",
    "output_path = args.output\n",
    "TARGET_SIZE = 128\n",
    "\n",
    "def resize_and_save(img, save_file_path, size):\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    scale = size / max(h, w)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(img, (new_w, new_h))\n",
    "\n",
    "    # compute padding\n",
    "    top = (size - new_h) // 2\n",
    "    bottom = size - new_h - top\n",
    "    left = (size - new_w) // 2\n",
    "    right = size - new_w - left\n",
    "\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        resized, top, bottom, left, right,\n",
    "        cv2.BORDER_CONSTANT, value=[0,0,0]\n",
    "    )\n",
    "        \n",
    "    # Save cropped image\n",
    "    cv2.imwrite(save_file_path, padded)\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(input_path, topdown=True):\n",
    "    for dir in dirs:\n",
    "        if not os.path.isdir(os.path.join(output_path, dir)):\n",
    "            os.makedirs(os.path.join(output_path, dir))\n",
    "    for file in files:\n",
    "        if not file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "        file = os.path.relpath(os.path.join(subdir, file), input_path)\n",
    "        \n",
    "# Load the input image.\n",
    "        input_file_path = os.path.join(input_path, file)\n",
    "        image = cv2.imread(input_file_path)\n",
    "\n",
    "# Resize and save image \n",
    "        output_file_path = os.path.join(output_path, file)\n",
    "        print(\"processing \", file, \"...\")\n",
    "        resize_and_save(image, output_file_path, TARGET_SIZE)\n",
    "        \n",
    "print(\"Done resizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8859c8b-90c1-40d9-9ec3-0d1a714e31e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb36e1-9257-4541-bc8b-c24ebb331fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d55a9-ddee-46d5-a3a0-04983c9276bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
