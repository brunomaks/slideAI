{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e08d132-6efa-4250-bada-558c15e79168",
   "metadata": {},
   "source": [
    "When we have cropped hand gesture images saved, they are all of different sizes. We want them to have an optimal size so that it is: \n",
    "1. Big enough to capture important hand-shape details\n",
    "2. Small enough to train fast\n",
    "3. Consistent across the dataset\n",
    "    \n",
    "So we chose to look at the distribution of all our image dimensions and choose a size close to the *median* or *mean*, then round to a CNN-friendly size (like 64, 96, 128). \n",
    "- *Motivation to this is:* Powers of 2 and Divisibility - many of these numbers are powers of 2 (64, 128, 256, which is close to 224 in practical terms) or easily divisible by 32. This is crucial because standard CNN architectures use multiple layers of pooling operations that typically reduce the image dimensions by half at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a18e61c-8919-4392-9608-b42df934addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean width:  75.06502242152466\n",
      "Mean height:  126.26083707025411\n",
      "Median width:  74.0\n",
      "Median height:  124.0\n",
      "Count:  1338\n",
      "Min size: 44 60\n",
      "Max size: 161 304\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_folder = \"./mediapipe_cropper/gestures_processed/train_point_up/\"\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "count = 0\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    img = cv2.imread(os.path.join(input_folder, filename))\n",
    "    h, w = img.shape[:2]\n",
    "    widths.append(w)\n",
    "    heights.append(h)\n",
    "\n",
    "print(\"Mean width: \", np.mean(widths))\n",
    "print(\"Mean height: \", np.mean(heights))\n",
    "print(\"Median width: \", np.median(widths))\n",
    "print(\"Median height: \", np.median(heights))\n",
    "\n",
    "print(\"Min size:\", min(widths), min(heights))\n",
    "print(\"Max size:\", max(widths), max(heights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2ebe4-12e4-4500-bfb5-7dc5072b99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import argparse \n",
    "import sys\n",
    "\n",
    "# Simulate command line arguments\n",
    "sys.argv = ['script.py', '-height', '128', '-width', '128', \n",
    "            '-input', './mediapipe_cropper/gestures_processed/train_point_up/', '-output', './resizer/output/']\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "#-h HEIGHT -w WIDTH -i INPUT -o OUTPUT \n",
    "parser.add_argument(\"-height\", \"--height\", dest = \"height\", default = 128, help=\"Output image height\", type=int)\n",
    "parser.add_argument(\"-width\", \"--width\", dest = \"width\", default = 128, help=\"Output image width\", type=int)\n",
    "parser.add_argument(\"-input\", \"--input\", dest = \"input\", default = \"./input/\", help=\"Path to input folder\")\n",
    "parser.add_argument(\"-output\", \"--output\", dest = \"output\", default = \"./output/\", help=\"Path to output folder\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "NEW_WIDTH = args.width\n",
    "NEW_HEIGHT = args.height\n",
    "input_path = args.input\n",
    "output_path = args.output\n",
    "\n",
    "\n",
    "def resize_and_save(image, save_file_path):\n",
    "    \n",
    "    resized_img = cv2.resize(image, (NEW_WIDTH, NEW_HEIGHT))\n",
    "        \n",
    "    # Save cropped image\n",
    "    cv2.imwrite(save_file_path, resized_img)\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(input_path, topdown=True):\n",
    "    for dir in dirs:\n",
    "        if not os.path.isdir(os.path.join(output_path, dir)):\n",
    "            os.makedirs(os.path.join(output_path, dir))\n",
    "    for file in files:\n",
    "        if not file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "        file = os.path.relpath(os.path.join(subdir, file), input_path)\n",
    "        \n",
    "# Load the input image.\n",
    "        input_file_path = os.path.join(input_path, file)\n",
    "        image = cv2.imread(input_file_path)\n",
    "\n",
    "# Resize and save image \n",
    "        output_file_path = os.path.join(output_path, file)\n",
    "        print(\"processing \", file, \"...\")\n",
    "        resize_and_save(image, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8859c8b-90c1-40d9-9ec3-0d1a714e31e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb36e1-9257-4541-bc8b-c24ebb331fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
